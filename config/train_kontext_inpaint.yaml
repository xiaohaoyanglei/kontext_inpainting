---
job: extension
config:
  # 基于 FLUX.1-Fill 的 Kontext-inpaint 伪 mask-free 全模型 fine-tune 配置
  name: "flux_fill_kontext_inpaint_v1"
  process:
    - type: 'sd_trainer'
      # 训练输出文件夹
      training_folder: "/cloud/cloud-ssd1/training_output"
      device: cuda:0
      

      # 保存配置
      save:
        dtype: bf16 # 精度保存
        save_every: 500 # 每500步保存一次
        max_step_saves_to_keep: 3 # 保留最近3个检查点
        push_to_hub: false
        
      # 数据集配置：使用 WhiteMaskDataset
      datasets:
        # 注意：这里使用自定义的 WhiteMaskDataset
        # 它会自动生成纯白控制图像，无需手动提供mask
        - folder_path: "/cloud/cloud-ssd1/my_dataset/source_images"  # 原图路径
          # 目标图像路径（编辑后的结果）
          target_path: "/cloud/cloud-ssd1/my_dataset/target_images"
          # 不需要 mask_path，WhiteMaskDataset 会自动生成纯白控制图
          caption_ext: "txt"
          caption_dropout_rate: 0.05  # 5% 概率丢弃caption
          cache_latents_to_disk: true  # 缓存latent到磁盘
          shuffle_tokens: false
          # Kontext 在2x latent尺寸运行，512分辨率较为安全
          resolution: 512
          # 使用我们新创建的 WhiteMaskDataset
          dataset_class: "WhiteMaskDataset"
          
      # 训练配置：两阶段 fine-tune
      train:
        batch_size: 1
        steps: 3000  # 总训练步数（阶段1：1000步，阶段2：2000步）
        gradient_accumulation_steps: 4  # 梯度累积
        train_unet: true
        train_text_encoder: false  # FLUX不建议训练文本编码器
        gradient_checkpointing: true  # 节省显存
        noise_scheduler: "flowmatch" # 使用 Flow Matching
        optimizer: "adamw8bit"
        lr: 1e-4  # 第一阶段学习率（只训练projection层）
        timestep_type: "flux_shift"  # FLUX专用时间步
        dtype: bf16  # 混合精度训练
        
        # 两阶段训练配置
        two_stage_training: true
        stage1_steps: 1000  # 第一阶段：只训练 projection 层
        stage1_lr: 1e-4     # 第一阶段学习率
        stage2_lr: 5e-5     # 第二阶段学习率（全模型微调）
        
        # EMA配置（可选）
        ema_config:
          use_ema: false
          ema_decay: 0.99
          
      # 模型配置：基于本地 FLUX.1-Fill-dev 全模型 fine-tune
      model:
        # 使用本地 FLUX.1-Fill-dev 作为基础模型
        name_or_path: "/cloud/cloud-ssd1/FLUX.1-Fill-dev"
        arch: "flux_fill_inpaint"  # 基于 FLUX.1-Fill 的 inpaint 架构
        quantize: false  # 全模型微调时不量化
        
        # Kontext-inpaint 特定配置
        model_kwargs:
          kontext_inpaint_mode: true  # 启用伪 mask-free 模式
          init_projection_from_original: true  # 从原始16→hidden投影初始化32→hidden投影
          two_stage_training: true  # 启用两阶段训练
          stage1_steps: 1000  # 第一阶段步数
          stage1_lr: 1e-4     # 第一阶段学习率
          stage2_lr: 5e-5     # 第二阶段学习率
        # low_vram: true  # 如果GPU连接显示器可取消注释
        
      # 采样配置
      sample:
        sampler: "flowmatch"  # 必须匹配 train.noise_scheduler
        sample_every: 500  # 每500步采样一次
        width: 512
        height: 512
        prompts:
          # Kontext-inpaint 的测试提示词
          # 注意：--ctrl_img 将被自动设置为纯白图像
          - "make the person smile"
          - "change the background to a beach"
          - "add sunglasses to the person"
          - "turn this into a cartoon style"
          - "change the lighting to golden hour"
          - "add a hat to the person"
          - "change the person's hair color to blonde"
          - "make the scene more colorful"
        neg: ""  # FLUX不使用负提示词
        seed: 42
        walk_seed: true
        guidance_scale: 4.0
        sample_steps: 20

# 元信息
meta:
  name: "Kontext-inpaint v1"
  version: '1.0'
  description: "伪 mask-free 的 Kontext-inpaint 模型，基于纯白控制图像的多轮编辑"
  author: "Kontext-inpaint Team"
  notes: |
    此配置实现了伪 mask-free 的 inpainting 模型：
    - 输入：原图RGB(3) + 纯白RGB(3) → VAE编码 → 32通道latent
    - 输出：编辑后的RGB(3)图像
    - 保持 Kontext 的多轮一致性能力
    - 为 SeedVR2 风格扩展预留接口