#!/usr/bin/env python3
"""
FLUX Fill Inpainting Inference Script
ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹è¿›è¡Œinpaintingæ¨ç†
"""

import torch
import argparse
from PIL import Image
import os
from diffusers import FluxFillPipeline
from pathlib import Path


def load_pipeline(model_path, device="cuda", dtype=torch.bfloat16):
    """åŠ è½½FLUX Fill pipeline"""
    print(f"åŠ è½½æ¨¡å‹: {model_path}")
    
    # åŠ è½½pipeline
    pipeline = FluxFillPipeline.from_pretrained(
        model_path,
        torch_dtype=dtype,
        device_map=device
    )
    
    # å¯ç”¨å†…å­˜é«˜æ•ˆattention (å¦‚æœå¯ç”¨)
    try:
        pipeline.enable_model_cpu_offload()
        print("âœ… å¯ç”¨CPU offload")
    except:
        print("âš ï¸ CPU offloadä¸å¯ç”¨")
    
    try:
        pipeline.enable_attention_slicing()
        print("âœ… å¯ç”¨attention slicing")
    except:
        print("âš ï¸ Attention slicingä¸å¯ç”¨")
    
    return pipeline


def prepare_images(source_path, mask_path, target_size=(512, 512)):
    """å‡†å¤‡è¾“å…¥å›¾åƒ"""
    # åŠ è½½sourceå›¾åƒ
    source_image = Image.open(source_path)
    if source_image.mode != 'RGB':
        source_image = source_image.convert('RGB')
    
    # åŠ è½½maskå›¾åƒ
    mask_image = Image.open(mask_path)
    if mask_image.mode != 'L':
        mask_image = mask_image.convert('L')
    
    # è°ƒæ•´å°ºå¯¸
    source_image = source_image.resize(target_size, Image.LANCZOS)
    mask_image = mask_image.resize(target_size, Image.LANCZOS)
    
    return source_image, mask_image


def run_inference(pipeline, source_image, mask_image, prompt, 
                 num_inference_steps=20, guidance_scale=4.0, seed=None):
    """è¿è¡Œæ¨ç†"""
    
    generator = None
    if seed is not None:
        generator = torch.Generator(device=pipeline.device).manual_seed(seed)
        print(f"ä½¿ç”¨éšæœºç§å­: {seed}")
    
    print(f"å¼€å§‹æ¨ç†...")
    print(f"  æç¤ºè¯: {prompt}")
    print(f"  æ¨ç†æ­¥æ•°: {num_inference_steps}")
    print(f"  å¼•å¯¼å¼ºåº¦: {guidance_scale}")
    
    # è¿è¡Œæ¨ç†
    with torch.no_grad():
        result = pipeline(
            prompt=prompt,
            image=source_image,
            mask_image=mask_image,
            num_inference_steps=num_inference_steps,
            guidance_scale=guidance_scale,
            generator=generator,
        )
    
    return result.images[0]


def main():
    parser = argparse.ArgumentParser(description="FLUX Fill Inpaintingæ¨ç†")
    parser.add_argument("--model_path", required=True, help="æ¨¡å‹è·¯å¾„")
    parser.add_argument("--source_image", required=True, help="æºå›¾åƒè·¯å¾„")
    parser.add_argument("--mask_image", required=True, help="maskå›¾åƒè·¯å¾„")
    parser.add_argument("--prompt", required=True, help="æ¨ç†æç¤ºè¯")
    parser.add_argument("--output", default="output.png", help="è¾“å‡ºå›¾åƒè·¯å¾„")
    parser.add_argument("--steps", type=int, default=20, help="æ¨ç†æ­¥æ•°")
    parser.add_argument("--guidance", type=float, default=4.0, help="å¼•å¯¼å¼ºåº¦")
    parser.add_argument("--seed", type=int, default=None, help="éšæœºç§å­")
    parser.add_argument("--size", type=int, default=512, help="å›¾åƒå°ºå¯¸")
    
    args = parser.parse_args()
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
    if not os.path.exists(args.source_image):
        print(f"âŒ æºå›¾åƒä¸å­˜åœ¨: {args.source_image}")
        return
    
    if not os.path.exists(args.mask_image):
        print(f"âŒ Maskå›¾åƒä¸å­˜åœ¨: {args.mask_image}")
        return
    
    print("ğŸš€ FLUX Fill Inpaintingæ¨ç†")
    print(f"ğŸ“ æ¨¡å‹è·¯å¾„: {args.model_path}")
    print(f"ğŸ–¼ï¸ æºå›¾åƒ: {args.source_image}")
    print(f"ğŸ­ Maskå›¾åƒ: {args.mask_image}")
    print(f"ğŸ’¬ æç¤ºè¯: {args.prompt}")
    
    # åŠ è½½pipeline
    try:
        pipeline = load_pipeline(args.model_path)
    except Exception as e:
        print(f"âŒ åŠ è½½æ¨¡å‹å¤±è´¥: {e}")
        return
    
    # å‡†å¤‡å›¾åƒ
    try:
        source_image, mask_image = prepare_images(
            args.source_image, 
            args.mask_image, 
            target_size=(args.size, args.size)
        )
        print(f"âœ… å›¾åƒé¢„å¤„ç†å®Œæˆ: {args.size}x{args.size}")
    except Exception as e:
        print(f"âŒ å›¾åƒå¤„ç†å¤±è´¥: {e}")
        return
    
    # è¿è¡Œæ¨ç†
    try:
        result_image = run_inference(
            pipeline=pipeline,
            source_image=source_image,
            mask_image=mask_image,
            prompt=args.prompt,
            num_inference_steps=args.steps,
            guidance_scale=args.guidance,
            seed=args.seed
        )
        
        # ä¿å­˜ç»“æœ
        result_image.save(args.output)
        print(f"âœ… æ¨ç†å®Œæˆ! ç»“æœä¿å­˜åˆ°: {args.output}")
        
    except Exception as e:
        print(f"âŒ æ¨ç†å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main() 